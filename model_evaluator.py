import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import silhouette_score, calinski_harabasz_score
import time

def evaluate_svm_model():
    """
    ƒê√°nh gi√° m√¥ h√¨nh SVM
    """
    print("=== ƒê√ÅNH GI√Å M√î H√åNH SVM ===")
    
    try:
        # Load model v√† d·ªØ li·ªáu
        svm_model = joblib.load('models/svm_model.joblib')
        scaler = joblib.load('models/scaler.joblib')
        
        # ƒê·ªçc d·ªØ li·ªáu test
        request_data = pd.read_csv('data/request_data.csv')
        X = request_data[['cpu_cores', 'memory_gb', 'storage_gb', 'network_bandwidth', 'priority']].values
        y = request_data['makespan_label'].values
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        X_scaled = scaler.transform(X)
        
        # D·ª± ƒëo√°n
        start_time = time.time()
        y_pred = svm_model.predict(X_scaled)
        prediction_time = time.time() - start_time
        
        # T√≠nh metrics
        accuracy = accuracy_score(y, y_pred)
        
        print(f"Accuracy: {accuracy:.4f}")
        print(f"Th·ªùi gian d·ª± ƒëo√°n trung b√¨nh: {prediction_time/len(X):.6f} gi√¢y/m·∫´u")
        print(f"T·ªïng th·ªùi gian d·ª± ƒëo√°n {len(X)} m·∫´u: {prediction_time:.4f} gi√¢y")
        
        # Classification report
        print("\nClassification Report:")
        print(classification_report(y, y_pred))
        
        # Confusion matrix
        cm = confusion_matrix(y, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['small', 'medium', 'large'],
                    yticklabels=['small', 'medium', 'large'])
        plt.title('Confusion Matrix - SVM Model Evaluation')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()
        plt.savefig('models/svm_evaluation.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return {
            'accuracy': accuracy,
            'prediction_time': prediction_time,
            'avg_prediction_time': prediction_time/len(X)
        }
        
    except FileNotFoundError as e:
        print(f"Kh√¥ng t√¨m th·∫•y file model: {e}")
        return None

def evaluate_kmeans_model():
    """
    ƒê√°nh gi√° m√¥ h√¨nh K-Means
    """
    print("\n=== ƒê√ÅNH GI√Å M√î H√åNH K-MEANS ===")
    
    try:
        # Load model v√† d·ªØ li·ªáu
        kmeans_model = joblib.load('models/kmeans_model.joblib')
        kmeans_scaler = joblib.load('models/kmeans_scaler.joblib')
        
        # ƒê·ªçc d·ªØ li·ªáu VM
        vm_data = pd.read_csv('data/vm_data.csv')
        features = ['cpu_usage', 'ram_usage', 'storage_usage']
        vm_features = vm_data[features]
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        vm_scaled = kmeans_scaler.transform(vm_features)
        
        # D·ª± ƒëo√°n c·ª•m
        start_time = time.time()
        cluster_labels = kmeans_model.predict(vm_scaled)
        prediction_time = time.time() - start_time
        
        # T√≠nh metrics
        silhouette_avg = silhouette_score(vm_scaled, cluster_labels)
        calinski_avg = calinski_harabasz_score(vm_scaled, cluster_labels)
        
        print(f"Silhouette Score: {silhouette_avg:.4f}")
        print(f"Calinski-Harabasz Score: {calinski_avg:.4f}")
        print(f"Th·ªùi gian d·ª± ƒëo√°n trung b√¨nh: {prediction_time/len(vm_features):.6f} gi√¢y/m·∫´u")
        print(f"T·ªïng th·ªùi gian d·ª± ƒëo√°n {len(vm_features)} m·∫´u: {prediction_time:.4f} gi√¢y")
        
        # Ph√¢n t√≠ch c·ª•m
        cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
        print(f"\nPh√¢n b·ªë c·ª•m:")
        for cluster_id, count in cluster_counts.items():
            percentage = (count / len(vm_features)) * 100
            print(f"  C·ª•m {cluster_id}: {count} VM ({percentage:.1f}%)")
        
        # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë c·ª•m
        plt.figure(figsize=(10, 5))
        
        plt.subplot(1, 2, 1)
        plt.pie(cluster_counts.values, labels=[f'C·ª•m {i}' for i in cluster_counts.index], 
                autopct='%1.1f%%', startangle=90)
        plt.title('Ph√¢n b·ªë VM theo c·ª•m')
        
        plt.subplot(1, 2, 2)
        plt.bar(cluster_counts.index, cluster_counts.values, color='skyblue')
        plt.xlabel('Cluster ID')
        plt.ylabel('S·ªë l∆∞·ª£ng VM')
        plt.title('S·ªë l∆∞·ª£ng VM trong m·ªói c·ª•m')
        plt.xticks(range(len(cluster_counts)))
        
        plt.tight_layout()
        plt.savefig('models/kmeans_evaluation.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return {
            'silhouette_score': silhouette_avg,
            'calinski_score': calinski_avg,
            'prediction_time': prediction_time,
            'avg_prediction_time': prediction_time/len(vm_features),
            'cluster_distribution': cluster_counts.to_dict()
        }
        
    except FileNotFoundError as e:
        print(f"Kh√¥ng t√¨m th·∫•y file model: {e}")
        return None

def compare_models():
    """
    So s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh
    """
    print("\n=== SO S√ÅNH HI·ªÜU SU·∫§T M√î H√åNH ===")
    
    svm_results = evaluate_svm_model()
    kmeans_results = evaluate_kmeans_model()
    
    if svm_results and kmeans_results:
        # T·∫°o b·∫£ng so s√°nh
        comparison_data = {
            'Metric': ['Accuracy/Quality Score', 'Prediction Time (ms/sample)', 'Total Prediction Time (s)'],
            'SVM': [
                f"{svm_results['accuracy']:.4f}",
                f"{svm_results['avg_prediction_time']*1000:.2f}",
                f"{svm_results['prediction_time']:.4f}"
            ],
            'K-Means': [
                f"{kmeans_results['silhouette_score']:.4f}",
                f"{kmeans_results['avg_prediction_time']*1000:.2f}",
                f"{kmeans_results['prediction_time']:.4f}"
            ]
        }
        
        comparison_df = pd.DataFrame(comparison_data)
        print("\nB·∫£ng so s√°nh hi·ªáu su·∫•t:")
        print(comparison_df.to_string(index=False))
        
        # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # So s√°nh th·ªùi gian d·ª± ƒëo√°n
        models = ['SVM', 'K-Means']
        prediction_times = [
            svm_results['avg_prediction_time']*1000,
            kmeans_results['avg_prediction_time']*1000
        ]
        
        axes[0].bar(models, prediction_times, color=['blue', 'orange'])
        axes[0].set_ylabel('Th·ªùi gian d·ª± ƒëo√°n (ms/m·∫´u)')
        axes[0].set_title('So s√°nh th·ªùi gian d·ª± ƒëo√°n')
        axes[0].set_ylim(0, max(prediction_times) * 1.2)
        
        # Th√™m gi√° tr·ªã l√™n c·ªôt
        for i, v in enumerate(prediction_times):
            axes[0].text(i, v + max(prediction_times) * 0.01, f'{v:.2f}ms', 
                        ha='center', va='bottom')
        
        # So s√°nh ch·∫•t l∆∞·ª£ng
        quality_scores = [svm_results['accuracy'], kmeans_results['silhouette_score']]
        quality_labels = ['Accuracy', 'Silhouette Score']
        
        axes[1].bar(models, quality_scores, color=['green', 'red'])
        axes[1].set_ylabel('Ch·∫•t l∆∞·ª£ng m√¥ h√¨nh')
        axes[1].set_title('So s√°nh ch·∫•t l∆∞·ª£ng m√¥ h√¨nh')
        axes[1].set_ylim(0, 1)
        
        # Th√™m gi√° tr·ªã l√™n c·ªôt
        for i, v in enumerate(quality_scores):
            axes[1].text(i, v + 0.01, f'{v:.4f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig('models/model_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # L∆∞u k·∫øt qu·∫£ so s√°nh
        comparison_df.to_csv('models/model_comparison_results.csv', index=False)
        print("\nüìä K·∫øt qu·∫£ so s√°nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o models/model_comparison_results.csv")

def generate_model_report():
    """
    T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªÅ c√°c m√¥ h√¨nh
    """
    print("\n=== T·∫†O B√ÅO C√ÅO M√î H√åNH ===")
    
    report = []
    report.append("# B√ÅO C√ÅO HU·∫§N LUY·ªÜN M√î H√åNH MACHINE LEARNING")
    report.append("")
    report.append("## 1. M√¥ h√¨nh SVM (Support Vector Machine)")
    report.append("")
    
    try:
        svm_model = joblib.load('models/svm_model.joblib')
        report.append(f"- **Kernel**: {svm_model.kernel}")
        report.append(f"- **C parameter**: {svm_model.C}")
        report.append(f"- **Gamma**: {svm_model.gamma}")
        report.append(f"- **S·ªë support vectors**: {sum(svm_model.n_support_)}")
        report.append(f"- **S·ªë l·ªõp**: {len(svm_model.classes_)}")
        report.append("")
    except:
        report.append("- Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh SVM")
        report.append("")
    
    report.append("## 2. M√¥ h√¨nh K-Means")
    report.append("")
    
    try:
        kmeans_model = joblib.load('models/kmeans_model.joblib')
        report.append(f"- **S·ªë c·ª•m**: {kmeans_model.n_clusters}")
        report.append(f"- **Inertia**: {kmeans_model.inertia_:.4f}")
        report.append(f"- **S·ªë l·∫ßn l·∫∑p**: {kmeans_model.n_iter_}")
        report.append("")
    except:
        report.append("- Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh K-Means")
        report.append("")
    
    report.append("## 3. C√°ch s·ª≠ d·ª•ng m√¥ h√¨nh")
    report.append("")
    report.append("### SVM Model:")
    report.append("```python")
    report.append("import joblib")
    report.append("")
    report.append("# Load model")
    report.append("svm_model = joblib.load('models/svm_model.joblib')")
    report.append("scaler = joblib.load('models/scaler.joblib')")
    report.append("")
    report.append("# D·ª± ƒëo√°n")
    report.append("features = [cpu_cores, memory_gb, storage_gb, network_bandwidth, priority]")
    report.append("features_scaled = scaler.transform([features])")
    report.append("prediction = svm_model.predict(features_scaled)[0]")
    report.append("```")
    report.append("")
    
    report.append("### K-Means Model:")
    report.append("```python")
    report.append("import joblib")
    report.append("")
    report.append("# Load model")
    report.append("kmeans_model = joblib.load('models/kmeans_model.joblib')")
    report.append("kmeans_scaler = joblib.load('models/kmeans_scaler.joblib')")
    report.append("")
    report.append("# D·ª± ƒëo√°n c·ª•m")
    report.append("vm_features = [cpu_usage, ram_usage, storage_usage]")
    report.append("vm_scaled = kmeans_scaler.transform([vm_features])")
    report.append("cluster = kmeans_model.predict(vm_scaled)[0]")
    report.append("```")
    report.append("")
    
    report.append("## 4. Files ƒë∆∞·ª£c t·∫°o")
    report.append("")
    report.append("- `models/svm_model.joblib`: M√¥ h√¨nh SVM ƒë√£ hu·∫•n luy·ªán")
    report.append("- `models/kmeans_model.joblib`: M√¥ h√¨nh K-Means ƒë√£ hu·∫•n luy·ªán")
    report.append("- `models/scaler.joblib`: Scaler cho SVM")
    report.append("- `models/kmeans_scaler.joblib`: Scaler cho K-Means")
    report.append("- `models/svm_grid_search.joblib`: K·∫øt qu·∫£ grid search SVM")
    report.append("- `models/kmeans_info.joblib`: Th√¥ng tin c·ª•m K-Means")
    report.append("")
    
    # L∆∞u b√°o c√°o
    with open('models/model_report.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print("üìÑ B√°o c√°o ƒë√£ ƒë∆∞·ª£c t·∫°o: models/model_report.md")

def main():
    """
    H√†m ch√≠nh ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh
    """
    print("=== ƒê√ÅNH GI√Å V√Ä SO S√ÅNH M√î H√åNH ===")
    
    # ƒê√°nh gi√° t·ª´ng m√¥ h√¨nh
    evaluate_svm_model()
    evaluate_kmeans_model()
    
    # So s√°nh m√¥ h√¨nh
    compare_models()
    
    # T·∫°o b√°o c√°o
    generate_model_report()
    
    print("\n‚úÖ Ho√†n th√†nh ƒë√°nh gi√° m√¥ h√¨nh!")

if __name__ == "__main__":
    main() 