# ğŸš€ HÆ°á»›ng dáº«n triá»ƒn khai ML Service + OpenResty lÃªn Amazon Cloud

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ triá»ƒn khai há»‡ thá»‘ng tÃ­ch há»£p ML Service (SVM + K-Means) vá»›i OpenResty lÃªn Amazon Cloud Ubuntu.

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- **OS**: Ubuntu 18.04+ hoáº·c Amazon Linux 2
- **RAM**: Tá»‘i thiá»ƒu 2GB (khuyáº¿n nghá»‹ 4GB+)
- **Storage**: Tá»‘i thiá»ƒu 10GB
- **Network**: Cá»•ng 80 vÃ  5000 má»Ÿ
- **Python**: 3.7+
- **OpenResty**: 1.15+

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client/Browserâ”‚    â”‚   OpenResty     â”‚    â”‚   ML Service    â”‚
â”‚                 â”‚    â”‚   (Port 80)     â”‚    â”‚   (Port 5000)   â”‚
â”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚â—„â”€â”€â–ºâ”‚                 â”‚
â”‚                 â”‚    â”‚ â€¢ API Gateway   â”‚    â”‚ â€¢ Flask API     â”‚
â”‚                 â”‚    â”‚ â€¢ Caching       â”‚    â”‚ â€¢ SVM Model     â”‚
â”‚                 â”‚    â”‚ â€¢ Load Balancingâ”‚    â”‚ â€¢ K-Means Model â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Triá»ƒn khai nhanh

### BÆ°á»›c 1: Chuáº©n bá»‹ server

```bash
# Káº¿t ná»‘i vÃ o Amazon EC2 instance
ssh -i your-key.pem ubuntu@your-ec2-ip

# Cáº­p nháº­t há»‡ thá»‘ng
sudo apt update && sudo apt upgrade -y
```

### BÆ°á»›c 2: Upload files

```bash
# Táº¡o thÆ° má»¥c project
mkdir ~/ml-openresty-integration
cd ~/ml-openresty-integration

# Upload táº¥t cáº£ files tá»« mÃ¡y local
# (Sá»­ dá»¥ng scp hoáº·c git clone)
scp -r /path/to/local/project/* ubuntu@your-ec2-ip:~/ml-openresty-integration/
```

### BÆ°á»›c 3: Cháº¡y script triá»ƒn khai

```bash
# Cáº¥p quyá»n thá»±c thi
chmod +x deploy.sh

# Cháº¡y script triá»ƒn khai
bash deploy.sh
```

### BÆ°á»›c 4: Kiá»ƒm tra triá»ƒn khai

```bash
# Test integration
python3 test_integration.py

# Kiá»ƒm tra services
sudo systemctl status ml-service
sudo systemctl status openresty
```

## ğŸ“ Cáº¥u trÃºc files sau triá»ƒn khai

```
/opt/ml-service/
â”œâ”€â”€ ml_service.py          # Flask API service
â”œâ”€â”€ models/                # ML models
â”‚   â”œâ”€â”€ svm_model.joblib
â”‚   â”œâ”€â”€ kmeans_model.joblib
â”‚   â”œâ”€â”€ scaler.joblib
â”‚   â””â”€â”€ kmeans_scaler.joblib
â”œâ”€â”€ venv/                  # Python virtual environment
â””â”€â”€ requirements.txt

/usr/local/openresty/nginx/conf/
â”œâ”€â”€ nginx.conf             # Main nginx config
â””â”€â”€ lua/                   # Lua scripts
    â”œâ”€â”€ predict_makespan.lua
    â”œâ”€â”€ predict_vm_cluster.lua
    â”œâ”€â”€ predict_batch.lua
    â”œâ”€â”€ vm_clusters_info.lua
    â”œâ”€â”€ models_info.lua
    â””â”€â”€ demo_page.lua

/etc/systemd/system/
â””â”€â”€ ml-service.service     # Systemd service
```

## ğŸ”§ Cáº¥u hÃ¬nh chi tiáº¿t

### ML Service (Flask API)

**File**: `/opt/ml-service/ml_service.py`

**Endpoints**:
- `GET /health` - Health check
- `POST /predict/makespan` - Dá»± Ä‘oÃ¡n makespan
- `POST /predict/vm_cluster` - Dá»± Ä‘oÃ¡n VM cluster
- `POST /predict/batch` - Dá»± Ä‘oÃ¡n hÃ ng loáº¡t
- `GET /vm_clusters/info` - ThÃ´ng tin cá»¥m VM
- `GET /models/info` - ThÃ´ng tin mÃ´ hÃ¬nh

### OpenResty Configuration

**File**: `/usr/local/openresty/nginx/conf/nginx.conf`

**Features**:
- API Gateway vá»›i caching
- CORS support
- Load balancing
- Error handling
- Performance optimization

### Systemd Services

**ML Service**: `/etc/systemd/system/ml-service.service`
- Auto-restart on failure
- Log management
- Environment isolation

## ğŸŒ Truy cáº­p vÃ  sá»­ dá»¥ng

### URLs chÃ­nh

```bash
# Demo page (giao diá»‡n web)
http://your-ec2-ip/demo

# Health check
http://your-ec2-ip/health

# API endpoints
http://your-ec2-ip/predict/makespan
http://your-ec2-ip/predict/vm_cluster
http://your-ec2-ip/predict/batch
http://your-ec2-ip/vm_clusters/info
http://your-ec2-ip/models/info

# Direct ML service (ná»™i bá»™)
http://localhost:5000/health
```

### VÃ­ dá»¥ sá»­ dá»¥ng API

#### 1. Dá»± Ä‘oÃ¡n Makespan

```bash
curl -X POST http://your-ec2-ip/predict/makespan \
  -H "Content-Type: application/json" \
  -d '{
    "features": [4, 8, 100, 1000, 3]
  }'
```

**Response**:
```json
{
  "makespan": "small",
  "confidence": 2.325,
  "features": [4, 8, 100, 1000, 3],
  "timestamp": "2024-01-01T12:00:00"
}
```

#### 2. Dá»± Ä‘oÃ¡n VM Cluster

```bash
curl -X POST http://your-ec2-ip/predict/vm_cluster \
  -H "Content-Type: application/json" \
  -d '{
    "vm_features": [0.7, 0.6, 0.4]
  }'
```

**Response**:
```json
{
  "cluster": 0,
  "distance": 0.720,
  "centroid": [1.013, -0.288, -0.884],
  "vm_features": [0.7, 0.6, 0.4],
  "timestamp": "2024-01-01T12:00:00"
}
```

#### 3. Batch Prediction

```bash
curl -X POST http://your-ec2-ip/predict/batch \
  -H "Content-Type: application/json" \
  -d '{
    "requests": [[4, 8, 100, 1000, 3], [8, 16, 200, 2000, 4]],
    "vm_usages": [[0.7, 0.6, 0.4], [0.5, 0.8, 0.6]]
  }'
```

## ğŸ” Monitoring vÃ  Logs

### Kiá»ƒm tra tráº¡ng thÃ¡i services

```bash
# ML Service status
sudo systemctl status ml-service

# OpenResty status
sudo systemctl status openresty

# Check ports
sudo netstat -tlnp | grep -E ':(80|5000)'
```

### Xem logs

```bash
# ML Service logs
sudo journalctl -u ml-service -f

# OpenResty logs
sudo tail -f /var/log/nginx/access.log
sudo tail -f /var/log/nginx/error.log

# System logs
sudo journalctl -f
```

### Performance monitoring

```bash
# Check memory usage
free -h

# Check CPU usage
top

# Check disk usage
df -h

# Check network connections
ss -tuln
```

## ğŸ› ï¸ Troubleshooting

### ML Service khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Check logs
sudo journalctl -u ml-service -n 50

# Check Python environment
cd /opt/ml-service
source venv/bin/activate
python ml_service.py

# Check file permissions
ls -la /opt/ml-service/
```

### OpenResty khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Test nginx config
sudo /usr/local/openresty/nginx/sbin/nginx -t

# Check nginx logs
sudo tail -f /var/log/nginx/error.log

# Check port conflicts
sudo lsof -i :80
```

### API khÃ´ng pháº£n há»“i

```bash
# Test connectivity
curl -v http://localhost/health
curl -v http://localhost:5000/health

# Check firewall
sudo ufw status

# Test ML service directly
curl -X POST http://localhost:5000/predict/makespan \
  -H "Content-Type: application/json" \
  -d '{"features": [4, 8, 100, 1000, 3]}'
```

## ğŸ”„ Maintenance

### Cáº­p nháº­t ML models

```bash
# Stop ML service
sudo systemctl stop ml-service

# Backup old models
sudo cp -r /opt/ml-service/models /opt/ml-service/models.backup

# Copy new models
sudo cp new_models/* /opt/ml-service/models/

# Start ML service
sudo systemctl start ml-service

# Test new models
python3 test_integration.py
```

### Restart services

```bash
# Restart ML service
sudo systemctl restart ml-service

# Restart OpenResty
sudo systemctl restart openresty

# Restart both
sudo systemctl restart ml-service openresty
```

### Backup vÃ  restore

```bash
# Backup
sudo tar -czf ml-service-backup-$(date +%Y%m%d).tar.gz /opt/ml-service/

# Restore
sudo tar -xzf ml-service-backup-20240101.tar.gz -C /
```

## ğŸ“Š Performance Optimization

### Caching

- **ML Cache**: 10MB shared memory cho predictions
- **VM Info Cache**: 5MB shared memory cho cluster info
- **TTL**: 5 phÃºt cho predictions, 10 phÃºt cho info

### Load Balancing

- **Keep-alive**: 32 connections
- **Timeout**: 5s connect, 10s read/write
- **Connection pooling**: Enabled

### Monitoring

```bash
# Install monitoring tools
sudo apt install -y htop iotop nethogs

# Monitor real-time
htop
iotop
nethogs
```

## ğŸ”’ Security

### Firewall configuration

```bash
# Allow only necessary ports
sudo ufw allow 22/tcp    # SSH
sudo ufw allow 80/tcp    # HTTP
sudo ufw deny 5000/tcp   # Block direct ML service access

# Enable firewall
sudo ufw enable
```

### SSL/TLS (Optional)

```bash
# Install certbot
sudo apt install -y certbot python3-certbot-nginx

# Get SSL certificate
sudo certbot --nginx -d your-domain.com

# Auto-renewal
sudo crontab -e
# Add: 0 12 * * * /usr/bin/certbot renew --quiet
```

## ğŸ“ˆ Scaling

### Horizontal scaling

1. **Load Balancer**: Sá»­ dá»¥ng AWS ALB
2. **Multiple ML Services**: Cháº¡y nhiá»u instances
3. **Database**: Redis cho shared cache
4. **Monitoring**: CloudWatch metrics

### Vertical scaling

1. **Increase RAM**: TÄƒng shared memory cache
2. **Increase CPU**: Tá»‘i Æ°u model inference
3. **SSD Storage**: TÄƒng I/O performance

## ğŸ†˜ Support

### Logs location

- **ML Service**: `sudo journalctl -u ml-service`
- **OpenResty**: `/var/log/nginx/`
- **System**: `/var/log/syslog`

### Common issues

1. **Port 80 in use**: `sudo lsof -i :80`
2. **Permission denied**: `sudo chown -R $USER:$USER /opt/ml-service/`
3. **Python import error**: Check virtual environment
4. **Model not found**: Verify model files exist

### Contact

- **Documentation**: Check this README
- **Issues**: Create GitHub issue
- **Support**: Contact system administrator

---

**ğŸ‰ ChÃºc má»«ng! Há»‡ thá»‘ng ML Service + OpenResty Ä‘Ã£ Ä‘Æ°á»£c triá»ƒn khai thÃ nh cÃ´ng!** 